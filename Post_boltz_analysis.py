import os
import json
from annotate_v import annotate
import time
import math

start = time.time()

""" This script will be used to analyse the predictions generated by the
clones from the NGS results of the phage selection biopanning experiments.
The script will extract key metrics of the protein folding predictions, such as confidence_score,ptm iptm """

raadict = {
        'A': 'ALA',
        'R': 'ARG',
        'N': 'ASN',
        'D': 'ASP',
        'C': 'CYS',
        'Q': 'GLN',
        'E': 'GLU',
        'G': 'GLY',
        'H': 'HIS',
        'I': 'ILE',
        'L': 'LEU',
        'K': 'LYS',
        'M': 'MET',
        'F': 'PHE',
        'P': 'PRO',
        'S': 'SER',
        'T': 'THR',
        'W': 'TRP',
        'Y': 'TYR',
        'V': 'VAL',
    }

def pdb_to_fasta(pdb_file):
    """
    Converts a PDB file to a FASTA file, separating sequences by chain and indexing amino acids.

    Args:
        pdb_file (str): Path to the input PDB file.
        output_dir (str): Path to the output directory.
    """

    aa_dict = {
        'ALA': 'A',
        'ARG': 'R',
        'ASN': 'N',
        'ASP': 'D',
        'CYS': 'C',
        'GLN': 'Q',
        'GLU': 'E',
        'GLY': 'G',
        'HIS': 'H',
        'ILE': 'I',
        'LEU': 'L',
        'LYS': 'K',
        'MET': 'M',
        'PHE': 'F',
        'PRO': 'P',
        'SER': 'S',
        'THR': 'T',
        'TRP': 'W',
        'TYR': 'Y',
        'VAL': 'V',
    }

    sequences = {}
    residue_numbers = {}

    with open(pdb_file, 'r') as f_in:
        for line in f_in:
            if line.startswith('ATOM') or line.startswith("HETATM"):
                residue_name = line.split(" ")[5]
                chain_id = line.split(" ")[9]
                residue_number = int(line.split(" ")[6])

                if residue_name in aa_dict:
                    if chain_id not in sequences:
                        sequences[chain_id] = ''
                        residue_numbers[chain_id] = []
                    if residue_number not in residue_numbers[chain_id]:
                        sequences[chain_id] += aa_dict[residue_name]
                        residue_numbers[chain_id].append(residue_number)
    return(sequences)


def jsonextractor(prediction_dir, model_name):
    """enavigates into boltz result subdirectories and extracts best model metrics
    asjust the perchain iptm index for the interractiosn of interest"""
    jsonfilepath = prediction_dir + "\\" + "confidence_" + model_name + "_model_0.json"
    with open(jsonfilepath) as json_file:
        json_data = json.load(json_file)
        confidence_score = json_data['confidence_score']
        iptm = json_data['iptm']
        perchain_itpm = json_data['pair_chains_iptm']['0']['1'], json_data['pair_chains_iptm']['0']['2'], json_data['pair_chains_iptm']['1']['2']
        """This as set extract iPTM for chain A:B(antigen:heavy), A:C(antigen:light), B:C(heavh:light)"""
    return (confidence_score, iptm, perchain_itpm)

path = "C:\\Users\\John-PaulAyrton\\Downloads\\boltz_results_NGS_clone_Gen\\predictions"
files = os.listdir(path)



text_file = open("Output.txt", "w")

### Ajdust THis!!
text_file.write("name\tconfidence_score\tIPTM\tpci_AB\tpci_AC\tpci_BC\tHeavy_chain_aa\tLight_chain_aa\tLCDR3_distance\tHCDR3_distance\n")

for file in files:
    subpath = path + "\\" + file
    name = file

    #extract metrics
    [confidence_score,iptm,per_chain_iptm] = jsonextractor(subpath,file)
    pci_AB = per_chain_iptm[0]
    pci_AC = per_chain_iptm[1]
    pci_BC = per_chain_iptm[2]
    print("name",name,"confidence_score",confidence_score,    "pci_AB", pci_AB,    "pci_AC", pci_AC,    "pci_BC", pci_BC    )
    pdbfile = subpath + "\\" + file + "_model_0.cif"

    ##etract HCDR3 and LCDR3
    sequences = pdb_to_fasta(pdbfile)

    ##lightchain distance
    print(sequences['C'])

    Laaseq =sequences['C']
    scheme="chothia"

    seq=annotate(Laaseq, scheme)

    result=seq.retrieve()


    LCDR3 = result[0]['L-CDR3']
    Laaseq = sequences['C']

    """if aa = ABABA
            mid =^
        if aa = ABABAB
            mid =  ^     basically when len LCDR3 is even round up"""
    for i in range(len(Laaseq) - len(LCDR3) + 1):
        if Laaseq[i:i + len(LCDR3)] == LCDR3:
            ii = i
            break
    lcdr3_mid_indx = ii + round(len(LCDR3) / 2) + 1
    lcdr3_mid_aa = raadict[Laaseq[i + round(len(LCDR3) / 2)]]

    ##heavychain distance
    Haaseq = sequences['B']
    scheme = "chothia"

    seq = annotate(Haaseq, scheme)

    result = seq.retrieve()

    HCDR3 = result[0]['H-CDR3']

    """if aa = ABABA
            mid =^
        if aa = ABABAB
            mid =  ^     basically when len LCDR3 is even round up"""
    for i in range(len(Haaseq) - len(HCDR3) + 1):
        if Haaseq[i:i + len(HCDR3)] == HCDR3:
            iii = i
            break
    HCDR3_mid_indx = iii + round(len(HCDR3) / 2) + 1
    HCDR3_mid_aa = raadict[Haaseq[i + round(len(HCDR3) / 2)]]
    seqqq = 0
    #for i in range(len(aaseq)):
    Hotspot_residue_coordinate = []
    LCDR3peak_residue_coordinate = []
    HCDR3peak_residue_coordinate = []
    f = open(pdbfile, 'r')
    file_contents = f.read().split("\n")
    index_srt = file_contents.index("_atom_site.pdbx_PDB_model_num") + 1

    for i in range(index_srt, len(file_contents)):
        if file_contents[i].find("C CA . "+lcdr3_mid_aa+" " +str(lcdr3_mid_indx) + " "+str(lcdr3_mid_indx)+" "+"? C") >=0:
            LCDR3peak_residue_coordinate = file_contents[i].split(" ")[10:13]
        elif file_contents[i].find("C CA . "+HCDR3_mid_aa+" " +str(HCDR3_mid_indx) + " "+str(HCDR3_mid_indx)+" "+"? B") >=0:
            HCDR3peak_residue_coordinate = file_contents[i].split(" ")[10:13]

        elif file_contents[i].find("C CA . LEU 103 103 ? A ") >=0:
            Hotspot_residue_coordinate = file_contents[i].split(" ")[10:13]

    LCDR3_distance = math.sqrt(((float(LCDR3peak_residue_coordinate[0]) - float(Hotspot_residue_coordinate[0])) ** 2) + ((float(LCDR3peak_residue_coordinate[1]) - float(Hotspot_residue_coordinate[1])) ** 2) + ((float(LCDR3peak_residue_coordinate[2]) - float(Hotspot_residue_coordinate[2])) ** 2))
    HCDR3_distance = math.sqrt(((float(HCDR3peak_residue_coordinate[0]) - float(Hotspot_residue_coordinate[0])) ** 2) + ((float(HCDR3peak_residue_coordinate[1]) - float(Hotspot_residue_coordinate[1])) ** 2) + ((float(HCDR3peak_residue_coordinate[2]) - float(Hotspot_residue_coordinate[2])) ** 2))
    text_file.write(f"{name}\t{confidence_score}\t{iptm}\t{pci_AB}\t{pci_AC}\t{pci_BC}\t{sequences['B']}\t{sequences['C']}\t{LCDR3_distance}\t{HCDR3_distance}\n")



end = time.time()
print(end - start)


"""to do Check coordinate extraction
    calculate distance of hotspot residue to peak h and L loop
    tabulate all metrics
    good luck 
    """
